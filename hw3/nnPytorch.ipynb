{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating data of 3 dim input and 2 dim output\n",
    "n, d = 500, 3\n",
    "x = torch.FloatTensor(n, d).uniform_(-1, 1)\n",
    "weights_true = torch.tensor([[5,1,5],[1,2,1]]).float()\n",
    "weights_true = torch.transpose(weights_true,0,1)\n",
    "bias_true = torch.tensor([1,2])\n",
    "y_true = torch.mm(x**2,weights_true) + torch.mm(x,weights_true) + bias_true\n",
    "print(f'x: {x.shape}, weights: {weights_true.shape}, bias: {bias_true.shape}, y: {y_true.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSE:\n",
    "    def __call__(self, y_pred, y_true):\n",
    "        self.y_pred = y_pred\n",
    "        self.y_true = y_true\n",
    "        return torch.mean((y_pred - y_true) ** 2)\n",
    "\n",
    "    def backward(self): \n",
    "        n = self.y_true.shape[0]\n",
    "        self.gradient = 2. * (self.y_pred - self.y_true) / n\n",
    "        return self.gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear:\n",
    "    def __init__(self, input_dim: int, num_hidden: int = 1):\n",
    "        self.weights = torch.rand(input_dim, num_hidden)\n",
    "        self.bias = torch.zeros(num_hidden,)\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        self.x = x\n",
    "        return torch.mm(x, self.weights) + self.bias\n",
    "\n",
    "    def backward(self, gradient):\n",
    "        self.weights_gradient = torch.mm(torch.transpose(self.x,0,1), gradient)\n",
    "        self.bias_gradient = gradient.sum(0)\n",
    "        self.x_gradient = torch.mm(gradient, torch.transpose(self.weights,0,1))\n",
    "        return self.x_gradient\n",
    "\n",
    "    def update(self, lr):\n",
    "        self.weights = self.weights - lr * self.weights_gradient\n",
    "        self.bias = self.bias - lr * self.bias_gradient\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relu:\n",
    "    def __call__(self, input_):\n",
    "      self.input_ = input_\n",
    "      self.output = torch.clamp(self.input_, min=0, out=None)\n",
    "      return self.output\n",
    "    \n",
    "    def backward(self, output_gradient):\n",
    "      self.input_gradient = (self.input_ > 0) * output_gradient \n",
    "      return self.input_gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "class Model:\n",
    "    def __init__(self, input_dim, num_hidden):\n",
    "        self.linear1 = Linear(input_dim, num_hidden)\n",
    "        self.relu1 = Relu()\n",
    "        self.linear2 = Linear(num_hidden, 12) # Pick 12 as number of neurons in hidden layer\n",
    "        self.relu2 = Relu()\n",
    "        self.linear3 = Linear(12,2)\n",
    "    \n",
    "    # Forward pass\n",
    "    def __call__(self, x):\n",
    "        l1 = self.linear1(x)\n",
    "        r1 = self.relu1(l1)\n",
    "        l2 = self.linear2(r1)\n",
    "        r2 = self.relu2(l2)\n",
    "        l3 = self.linear3(r2)\n",
    "        return l3\n",
    "    \n",
    "    def backward(self, output_gradient):\n",
    "        linear3_gradient = self.linear3.backward(output_gradient)\n",
    "        relu2_gradient = self.relu2.backward(linear3_gradient)\n",
    "        linear2_gradient = self.linear2.backward(relu2_gradient)\n",
    "        relu1_gradient = self.relu1.backward(linear2_gradient)\n",
    "        linear1_gradient = self.linear1.backward(relu1_gradient)\n",
    "        return linear1_gradient\n",
    "\n",
    "    def update(self, lr):\n",
    "        self.linear3.update(lr)\n",
    "        self.linear2.update(lr)\n",
    "        self.linear1.update(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(x, y, model: Callable, loss: Callable, lr: float, num_epochs: int):\n",
    "    for epoch in range(num_epochs):\n",
    "        y_pred = model(x)\n",
    "        loss_value = loss(y_pred, y)\n",
    "        if epoch % 50 == 0:\n",
    "            print(f'Epoch {epoch}, loss {loss_value}')\n",
    "        gradient_from_loss = loss.backward()\n",
    "        model.backward(gradient_from_loss)\n",
    "        model.update(lr)\n",
    "\n",
    "loss = MSE()\n",
    "model = Model(d, 20)\n",
    "fit(x, y_true, model=model, loss=loss, lr=0.0035, num_epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "def plot_intereactive_3d(x, y, y_pred=None):\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter3d(x = x[:,0],\n",
    "                        y = x[:,1],\n",
    "                        z = y.reshape([-1]),\n",
    "                        opacity=0.5, mode='markers', name='Underlying Function'\n",
    "                        ))\n",
    "    if y_pred is not None:\n",
    "        fig.add_trace(go.Scatter3d(x = x[:,0],\n",
    "                    y = x[:,1],\n",
    "                    z = y_pred.reshape([-1]),\n",
    "                    opacity=0.5, mode='markers', name='Predicted Function'\n",
    "                    ))\n",
    "    fig.update_layout(scene = dict(\n",
    "                        xaxis_title='X1',\n",
    "                        yaxis_title='X2',\n",
    "                        zaxis_title='Y'),\n",
    "                        width=700,\n",
    "                        margin=dict(r=20, b=10, l=10, t=10))\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "X_reduced = TSNE(n_components=2).fit_transform(x)\n",
    "y_true_reduced = TSNE(n_components=1).fit_transform(y_true)\n",
    "y_pred_reduced = TSNE(n_components=1).fit_transform(model(x))\n",
    "print(f'X_reduced: {X_reduced.shape}, y_true_reduced: {y_true_reduced.shape}, y_pred_reduced: {y_pred_reduced.shape}')\n",
    "plot_intereactive_3d(X_reduced,y_true_reduced,y_pred_reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using built in functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class Linear(nn.Module):\n",
    "    def __init__(self, input_dim, num_hidden):\n",
    "        super(Linear, self).__init__()\n",
    "        self.init = torch.rand(input_dim, num_hidden).float()\n",
    "        self.weights = torch.nn.Parameter(self.init, requires_grad=True)\n",
    "        self.bias = torch.zeros(num_hidden,)\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        self.x = x\n",
    "        return torch.mm(x, self.weights) + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchModel(nn.Module):\n",
    "    def __init__(self, input_dim, num_hidden):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(input_dim, num_hidden)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(num_hidden, 12)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.linear3 = nn.Linear(12, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        l1 = self.linear1(x)\n",
    "        r1 = self.relu1(l1)\n",
    "        l2 = self.linear2(r1)\n",
    "        r2 = self.relu2(l2)\n",
    "        l3 = self.linear3(r2)\n",
    "        return l3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_fit(x, y, model: Callable, loss: Callable, lr: float, num_epochs: int):\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "    for epoch in range(num_epochs):\n",
    "        optimizer.zero_grad() # Initialize gradient as zero\n",
    "        y_pred = model(x) # Forward Pass\n",
    "        loss_value = loss(y_pred, y) # Compute loss with MSE\n",
    "        if epoch % 50 == 0:\n",
    "            print(f'Epoch {epoch}, loss {loss_value}')\n",
    "        loss_value.backward() # Use autogradient to compute backward pass\n",
    "        optimizer.step() # Update weights \n",
    "\n",
    "loss = nn.MSELoss()\n",
    "model = TorchModel(d, 22)\n",
    "torch_fit(x, y_true, model=model, loss=loss, lr=0.035, num_epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reduced = TSNE(n_components=2).fit_transform(x)\n",
    "y_true_reduced = TSNE(n_components=1).fit_transform(y_true)\n",
    "y_pred_reduced = TSNE(n_components=1).fit_transform(model(x).detach())\n",
    "print(f'X_reduced: {X_reduced.shape}, y_true_reduced: {y_true_reduced.shape}, y_pred_reduced: {y_pred_reduced.shape}')\n",
    "plot_intereactive_3d(X_reduced,y_true_reduced,y_pred_reduced)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0e4631f8abf22b6e3bad75ef6fc74e8156bc6d7eda16a6da5468122f1c7f4a75"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
